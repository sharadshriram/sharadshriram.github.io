---
title: "Sharad Shriram"
layout: "single"
---

## üóûÔ∏è Latest News
- üíº July, 2022: Starting as a Pre-Doctoral Researcher at Google Research India.
- üíº August, 2021: Starting as Data Commons associate for the [Data Commons](https://datacommons.org/about) project hosted at Google.
- üìÑ May, 2021: Our work to model the impact of cohorted travelling in Mumbai locals is accepted as an extended abstract at AAMAS 2021

## About 
For a brief and compact overview, take a look at my 1-page [CV](../docs/Sharad_Shriram_1pgCV.pdf).

Between mid-2021 and mid-2022, I was a full-time contributor to the [DataCommons](https://datacommons.org), the open knowledge graph project at Google. My contributions were mainly in expanding the data coverage and defining new schema on the knowledge graph. The project resonates with my desire to have a unified data store, where public data is cleaned, and curated for machine consumption.

The early days of my career was at the [Centre for Networked Intelligence](https://cni.iisc.ac.in) at the Indian Insitute of Science, Bangalore where I was supervised by [Prof. Rajesh Sundaresan](https://eecs.iisc.ac.in/people/rajesh-sundaresan/) between late-2019 and mid-2021. My contributions were mainly in projects apart of the [centre's COVID-19 response efforts](https://cni.iisc.ac.in/covid-19-response/). 

I have received my Masters degree in Computer Science from the [Delft University of Technology, Delft, NL](https://tudelft.nl/en/)(2019) and my Bachelors degree in Computer Science from [Amrita Vishwa Vidyapeetham, Coimbatore, IN](https://amrita.edu/)(2016).


### Research
My current research interests is in the broader topic of Natural Language Understanding and I'm also keen to pursue some research along the following directions:
* Studying faithfulness and factuality of content generated by AI
* Studying methods that allow for machine models to abstain from predictions
* Studying algorithmic methods to determine when a model should abstain and defer to humans - along the lines of my [master's thesis](https://repository.tudelft.nl/islandora/object/uuid:30846529-9080-4945-8502-dc962ec00bf3)
* Understanding how to translate qualitative indicators and measures for trust and safety in AI to model training and development.
